{
  "hash": "153a42ea9917a364355c803ac083428b",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Sampling and Uncertainty\ndate: today\ndate-format: long\nfooter: \"[IAFF 6501 Website](https://quant4ia.rocks/)\"\nlogo: images/iaff6501-logo.png\nformat:\n  revealjs:\n    theme: [simple, custom.scss]\n    transition: fade\n    slide-number: true\n    #multiplex: true\n    chalkboard: true\nexecute:\n  echo: false\n  message: false\n  warning: false\n  freeze: auto\n---\n\n\n## Sampling\n\n::: incremental\n- **Sampling** the act of selecting a subset of individuals, items, or data points from a larger population to estimate characteristics or metrics of the entire population\n- Versus a **census**, which involves gathering information on every individual in the population\n- Why would you want to use a sample?\n:::\n\nToday's code is [HERE](https://www.dropbox.com/scl/fo/k6q8n5lbwbff6j0h5vvs1/AK9Ibhnd8t3rxV5FneYf8AU?rlkey=zo2rejko587tfvoq8tterd44r&dl=0)\n\n# Sampling Activity\n\n## What proportion of all milk chocolate M&Ms are blue?\n\n-   M&Ms has a precise distribution of colors that it produces in its factories\n-   M&Ms are sorted into bags in factories in a fairly random process\n-   Each bag represents a **sample** from the full **population** of M&Ms\n\n## Activity\n\n-   Get in groups of 2. Each group will have 4-5 bags of M&Ms.\n-   Keep the contents of each bag separate, and do not eat (yet!)\n-   Open up your first bag of M&Ms: calculate the proportion of the M&Ms that are blue. **Write this down.** What is your best guess (your **estimate**) for the proportion of all M&Ms that are blue?\n\n## Activity\n\n-   Do the same as above for the rest of your bags (you should have 4-5 **estimates** written down)\n-   Draw a histogram of your estimates (by hand)\n-   Add your estimates to this [Google Sheet](https://docs.google.com/spreadsheets/d/136wGKZOnwOdo3O-4bUfF_TWKBCAWQUCyiVKSY4HyYAw/edit?usp=sharing)\n-   Add your estimates to the class histogram on the whiteboard\n\n## Let's Analyze the Data\n\n<br>\n\nWe will use the `googlesheets4` package to pull the data into R so be sure to install it.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#install.packages(\"googlesheets4\")\n\nlibrary(tidyverse)\nlibrary(googlesheets4)\n\ngs4_deauth() # to signify no authorization required\n\nmnm_data <- read_sheet(\"https://docs.google.com/spreadsheets/d/136wGKZOnwOdo3O-4bUfF_TWKBCAWQUCyiVKSY4HyYAw/edit#gid=0\")\n\nglimpse(mnm_data)\n```\n:::\n\n\n\n## Calculate Some Summary Stats\n\n<br>\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmnm_data |>\n  summarize(\n    mean_blue = mean(proportion_blue),\n    median_blue = median(proportion_blue),\n    sd_blue = sd(proportion_blue)\n  )\n```\n:::\n\n\n## Now Let's Make a Histogram \n\n<br>\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(mnm_data, aes(x = proportion_blue)) +\n  geom_histogram(fill = \"steelblue\") +\n  labs(\n    title = \"Percentage of Blue M&Ms\",\n    x = \"Proportion Blue\",\n    y = \"Count\"\n  )\n```\n:::\n\n\n## Discuss with Neighbor \n\n-   What is the histogram/distribution showing?\n-   Based on the histogram on the board, what is your answer to the question of what proportion of all milk chocolate M&Ms are blue? Why do you give that answer?\n-   Why do some bag of M&Ms have proportions of blues that are higher and lower than the number you gave above?\n-   How do our estimates relate to the actual percentage of blue M&Ms manufactured (ask Google or ChatGPT)\n\n## What did we just do?\n\n::: incremental\n-   We wanted to say something about the **population** of M&Ms\n-   The **parameter** we care about is the proportion of M&Ms that are blue\n-   It would be impossible to conduct a **census** and to calculate the parameter\n-   We took a **sample** from the population and calculated a **sample statistic**\n-   **statistical inference:** act of making a guess about a **population** using information from a **sample**\n:::\n\n## What did we just do?\n\n::: incremental\n-   We completed this task many times\n-   This produced a **sampling distribution** of our **estimates**\n-   There is a distribution of estimates because of **sampling variability** \n-   Due to random chance, one estimate from one sample can differ from another\n-   These are foundational ideas for statistical inference that we are going to keep building on\n:::\n\n# Zooming Out\n\n## Target Population\n\nIn data analysis, we are usually interested in saying something about a **Target Population.**\n\n::: incremental\n-   What proportion of adult Russians support the war in Ukraine?\n    -   Target population: adult Russians (age 18+)\n-   How many US college students check social media during their classes?\n    -   Target population: US college students\n-   What percentage of M&Ms are blue?\n    -   Target population: all of the M&Ms\n:::\n\n## Sample\n\n<br>\n\nIn many instances, we have a **Sample**\n\n-   We cannot talk to every Russian\n-   We cannot talk to all college students\n-   We cannot count all of the M&Ms\n\n## Parameters vs Statistics\n\n<br>\n\n::: incremental\n-   The **parameter** is the value of a calculation for the entire target population\n-   The **statistic** is what we calculate on our sample\n    -   We calculate a statistic in order to say something about the parameter\n:::\n\n## Inference\n\n<br>\n\n::: incremental\n-   **Inference**--The act of \"making a guess\" about some unknown\n-   **Statistical inference**--Making a good guess about a population from a sample\n-   **Causal inference**--Did X cause Y? [topic for later classes]\n:::\n\n# Uncertainty\n\n## {.smaller}\n\nOn December 19, 2014, the front page of Spanish national newspaper El\nPaís read *\"Catalan public opinion swings toward 'no' for independence, says survey\"*.^[Alberto Cairo. [The truthful art: Data, charts, and maps for communication](http://www.thefunctionalart.com/p/the-truthful-art-book.html). New Riders, 2016.]\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](week-3.2_files/figure-revealjs/catalan-misleading-1.png){width=960}\n:::\n:::\n\n\n## {.smaller}\n\nThe probability of the tiny difference between the 'No' and 'Yes' being just due to random chance is very high.^[Alberto Cairo. [\"Uncertainty and Graphicacy\"](https://ec.europa.eu/eurostat/cros/powerfromstatistics/OR/PfS-OutlookReport-Cairo.pdf), 2017.]\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](week-3.2_files/figure-revealjs/unnamed-chunk-6-1.png){width=960}\n:::\n:::\n\n\n## Characterizing Uncertainty\n\n<br>\n\n- We know from previous section that even unbiased procedures do not get the \"right\" answer every time\n- We also know that our estimates might vary from sample to sample due to random chance\n- Therefore we want to report on our estimate and our level of uncertainty\n\n\n## Characterizing Uncertainty\n\n<br>\n\n- With M&Ms, we knew the population parameter\n- In real life, we do not!\n- We want to generate an estimate *and* characterize our uncertainty with a *range* of possible estimates\n    \n## Solution: Create a Confidence Interval\n\n<br>\n\n- A plausible range of values for the population parameter is a confidence interval.\n\n. . .\n\n- 95 percent confidence interval is standard\n    - We are 95% confident that the parameter value falls within the range given by the confidence interval\n\n## Ways to Estimate\n\n<br>\n\n- Take advantage of Central Limit Theorem to estimate using math\n- Use simulation, bootstrapping \n\n## With Math...\n\n$$CI = \\bar{x} \\pm Z \\left( \\frac{\\sigma}{\\sqrt{n}} \\right)$$\n\n- $\\bar{x}$ is the sample mean,\n- $Z$ is the Z-score corresponding to the desired level of confidence\n- $\\sigma$ is the population standard deviation, and \n- $n$ is the sample size\n\n## \n\n<br>\n\nThis part here represents the standard error: \n\n$$\\left( \\frac{\\sigma}{\\sqrt{n}} \\right)$$\n\n- Standard deviation of the sampling distribution\n- Characterizes the spread of the sampling distribution\n- The bigger this is the bigger the CIs are going to be\n\n## Central Limit Theorem\n\n$$CI = \\bar{x} \\pm Z \\left( \\frac{\\sigma}{\\sqrt{n}} \\right)$$\n\n- This way of doing things depends on the Central Limit Theorem\n- As sample size gets bigger, the spread of the sampling distribution gets narrower\n- The shape of the sampling distributions becomes more normally distributed\n\n## \n\n<br>\n\n$$CI = \\bar{x} \\pm Z \\left( \\frac{\\sigma}{\\sqrt{n}} \\right)$$\n\nThis is therefore a **parametric** method of calculating the CI. It depends on assumptions about the normality of the distribution.  \n\n## Bootstrapping\n\n<br>\n\n::: incremental\n- Pulling oneself up from their bootstraps ... \n- Use the data we have to estimate the sampling distribution\n- We call this the *bootstrap* distribution\n- This is a **nonparametric** method\n- It does not depend on assumptions about normality\n:::\n\n## Bootstrap Process {.smaller}\n\n<br>\n\n1. Take a bootstrap sample - a random sample taken **with replacement** from the original sample, of the **same size** as the original sample\n\n. . .\n\n2. Calculate the bootstrap statistic - a statistic such as mean, median, proportion, slope, etc. computed on the bootstrap samples\n\n. . .\n\n3. Repeat steps (1) and (2) many times to create a bootstrap distribution - a distribution of bootstrap statistics\n\n. . .\n\n4. Calculate the bounds of the XX% confidence interval as the middle XX% \nof the bootstrap distribution (usually 95 percent confidence interval)\n\n\n## Russia\n\n<br>\n\nWhat Proportion of Russians believe their country interfered in the 2016 presidential elections in the US?\n\n- Pew Research survey\n- 506 subjects\n- Data available in the `openintro` package\n\n## \n\n<br>\n\nFor this example, we will use data from the Open Intro package. Install that package before running this code chunk.\n\n<br>\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#install.packages(\"openintro\")\nlibrary(openintro)\n\nglimpse(russian_influence_on_us_election_2016)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 506\nColumns: 1\n$ influence_2016 <chr> \"Did not try\", \"Did not try\", \"Did not try\", \"Don't kno…\n```\n\n\n:::\n:::\n\n\n\n## \n\n<br>\n\nLet's use `mutate()` to recode the qualitative variable as a numeric one...\n\n<br>\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrussiaData <- russian_influence_on_us_election_2016 |> \n  mutate(try_influence = ifelse(influence_2016 == \"Did try\", 1, 0))\n```\n:::\n\n\n##\n\n<br>\n\nNow let's calculate the mean and standard deviation of the `try_influence` variable... \n\n<br>\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrussiaData |>\n  summarize( \n          mean = mean(try_influence),\n          sd = sd(try_influence)\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 2\n   mean    sd\n  <dbl> <dbl>\n1 0.150 0.358\n```\n\n\n:::\n:::\n\n\n## \n\n<br>\n\nAnd finally let's draw a bar plot...\n\n<br>\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(russiaData, aes(x = try_influence)) +\n  geom_bar(fill = \"steelblue\", width = .75) +\n  labs(\n    title = \"Did Russia try to influence the U.S. election?\",\n    x = \"0 = 'No', 1 = 'Yes'\",\n    y = \"Frequncy\"\n  ) +\n  theme_minimal()\n```\n:::\n\n\n## \n\n<br>\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](week-3.2_files/figure-revealjs/unnamed-chunk-11-1.png){width=960}\n:::\n:::\n\n\n## Bootstrap with `tidymodels`\n\nInstall `tidymodels` before running this code chunk... \n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"|1-2|4|5|6-7|8-9|10-11|13\"}\n#install.packages(\"tidymodels\")\nlibrary(tidymodels)\n\nset.seed(66)\nboot_dist <- russiaData |>\n  # specify the variable of interest\n  specify(response = try_influence) |>\n  # generate 10000 bootstrap samples\n  generate(reps = 10000, type = \"bootstrap\") |>\n  # calculate the mean of each bootstrap sample\n  calculate(stat = \"mean\")\n\nglimpse(boot_dist)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 10,000\nColumns: 2\n$ replicate <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 1…\n$ stat      <dbl> 0.1146245, 0.1442688, 0.1343874, 0.1877470, 0.1521739, 0.138…\n```\n\n\n:::\n:::\n\n\n## \n\n<br>\n\nCalculate the mean of the bootstrap distribution (of the means of the individual draws)...\n\n<br>\n\n\n::: {.cell}\n\n```{.r .cell-code}\nboot_dist |> summarize(mean = mean(stat))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 1\n   mean\n  <dbl>\n1 0.150\n```\n\n\n:::\n:::\n\n\n## \n\n<br>\n\nCalculate the confidence interval. A 95% confidence interval is bounded by the middle 95% of the bootstrap distribution.\n\n<br>\n\n\n::: {.cell}\n\n```{.r .cell-code}\nboot_dist |>\n  summarize(lower = quantile(stat, 0.025),\n            upper = quantile(stat, 0.975))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 2\n  lower upper\n  <dbl> <dbl>\n1 0.119 0.182\n```\n\n\n:::\n:::\n\n\n## \n\n<br>\n\nCreate upper and lower bounds for visualization.\n\n<br>\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# for using these values later\nlower_bound <- boot_dist |> summarize(lower_bound = quantile(stat, 0.025)) |> pull() \nupper_bound <- boot_dist |> summarize(upper_bound = quantile(stat, 0.975)) |> pull() \n```\n:::\n\n\n##\n\n<br>\n\nVisualize with a histogram\n\n<br>\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data = boot_dist, mapping = aes(x = stat)) +\n  geom_histogram(binwidth =.01, fill = \"steelblue4\") +\n  geom_vline(xintercept = c(lower_bound, upper_bound), color = \"darkgrey\", size = 1, linetype = \"dashed\") +\n  labs(title = \"Bootstrap distribution of means\",\n       subtitle = \"and 95% confidence interval\",\n       x = \"Estimate\",\n       y = \"Frequency\") +\n  theme_bw()\n```\n:::\n\n\n## \n\n<br>\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](week-3.2_files/figure-revealjs/unnamed-chunk-17-1.png){width=960}\n:::\n:::\n\n\n## Or use the `infer` package\n\n\n::: {.cell}\n\n```{.r .cell-code}\nci <- boot_dist |> get_ci(level = 0.95) \n\nci\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 2\n  lower_ci upper_ci\n     <dbl>    <dbl>\n1    0.119    0.182\n```\n\n\n:::\n:::\n\n\n## Or use the `infer` package\n\n\n::: {.cell}\n\n```{.r .cell-code}\nboot_dist |>\n  visualize() +\n  shade_ci(ci, color = \"red\", fill = NULL) +\n  labs( \n    title = \"Distribution of the Means of the Bootstrap Samples\",\n    x = \"Mean\",\n    y = \"Count\"\n  ) +\n  theme_minimal() \n```\n:::\n\n\n## Or use the `infer` package\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"2-3\"}\nboot_dist |>\n  visualize() +\n  shade_ci(ci, color = \"red\", fill = NULL) +\n  labs( \n    title = \"Distribution of the Means of the Bootstrap Samples\",\n    x = \"Mean\",\n    y = \"Count\"\n  ) +\n  theme_minimal() \n```\n:::\n\n\n## Interpret the confidence interval {.smaller}\n\n<br>\n\nThe 95% confidence interval was calculated as (`lower_bound`, `upper_bound`). Which of the following is the correct interpretation of this interval?\n\n<br>\n\n**(a)** 95% of the time the percentage of Russian who believe that Russia interfered in the 2016 US elections is between `lower_bound` and `upper_bound`.\n\n**(b)** 95% of all Russians believe that the chance Russia interfered in the 2016 US elections is between `lower_bound` and `upper_bound`.\n\n**(c)** We are 95% confident that the proportion of Russians who believe that Russia interfered in the 2016 US election is between `lower_bound` and `upper_bound`.\n\n**(d)** We are 95% confident that the proportion of Russians who supported interfering in the 2016 US elections is between `lower_bound` and `upper_bound`.\n\n## Your Turn! {.smaller}\n\n<br>\n\n- Change the `reps` argument in the `generate()` function to something way smaller, like 100. What happens to your estimates?\n- Try progressively higher numbers. What happens to your estimates as the number of reps increases?\n\n## Why did we do these simulations?\n\n<br>\n\n- They provide a foundation for statistical inference and for characterizing *uncertainty* in our estimates\n- The best **research designs** will try to maximize or achieve good balance on bias vs precision",
    "supporting": [
      "week-3.2_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}